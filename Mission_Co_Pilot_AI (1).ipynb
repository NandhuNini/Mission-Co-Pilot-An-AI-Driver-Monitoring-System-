{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUw3cNvgyfzI",
        "outputId": "c4ec1eb3-a500-47fc-8bee-f9baa4aa8e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.12/dist-packages (19.24.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python dlib numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOImXTj0ymuK",
        "outputId": "bed0aa22-f0e4-43ee-ab91-10ea99d3933c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-29 03:59:32--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-09-29 03:59:32--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  38.6MB/s    in 1.6s    \n",
            "\n",
            "2025-09-29 03:59:34 (38.6 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2: imports & helpers\n",
        "import cv2, dlib, math, time\n",
        "import numpy as np\n",
        "from imutils import face_utils\n",
        "from IPython.display import display, clear_output, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import imageio  # for saving GIFs later (pip installed above)"
      ],
      "metadata": {
        "id": "Bhbk5ItmMUL-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_head_pose(shape, img_size):\n",
        "    # img_size must be (height, width)\n",
        "    focal_length = img_size[1]\n",
        "    center = (img_size[1] / 2, img_size[0] / 2)\n",
        "    camera_matrix = np.array([\n",
        "        [focal_length, 0, center[0]],\n",
        "        [0, focal_length, center[1]],\n",
        "        [0, 0, 1]\n",
        "    ], dtype=\"double\")\n",
        "    dist_coeffs = np.zeros((4, 1))  # assume no lens distortion\n",
        "\n"
      ],
      "metadata": {
        "id": "6mRvQRuqK-6q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2: imports & helpers\n",
        "import cv2, dlib, math, time\n",
        "import numpy as np\n",
        "from imutils import face_utils\n",
        "from IPython.display import display, clear_output, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import imageio  # for saving GIFs later (pip installed above)\n",
        "\n",
        "# dlib detectors\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "# helper: convert dlib shape to numpy array (68,2)\n",
        "def shape_to_np(shape):\n",
        "    coords = np.zeros((68, 2), dtype=\"int\")\n",
        "    for i in range(0, 68):\n",
        "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "    return coords\n",
        "\n",
        "# Eye Aspect Ratio (EAR)\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "# Head pose helper: returns projected nose point and approximate euler angles (yaw, pitch, roll)\n",
        "def get_head_pose(shape, img_size):\n",
        "    image_points = np.array([\n",
        "        shape[30],     # nose tip\n",
        "        shape[8],      # chin\n",
        "        shape[36],     # left eye left corner\n",
        "        shape[45],     # right eye right corner\n",
        "        shape[48],     # left mouth corner\n",
        "        shape[54]      # right mouth corner\n",
        "    ], dtype='double')\n",
        "\n",
        "    model_points = np.array([\n",
        "        (0.0, 0.0, 0.0),\n",
        "        (0.0, -330.0, -65.0),\n",
        "        (-225.0, 170.0, -135.0),\n",
        "        (225.0, 170.0, -135.0),\n",
        "        (-150.0, -150.0, -125.0),\n",
        "        (150.0, -150.0, -125.0)\n",
        "    ], dtype='double')\n",
        "\n",
        "    focal_length = img_size[1]\n",
        "    center = (img_size[1] / 2, img_size[0] / 2)\n",
        "    camera_matrix = np.array([\n",
        "        [focal_length, 0, center[0]],\n",
        "        [0, focal_length, center[1]],\n",
        "        [0, 0, 1]\n",
        "    ], dtype=\"double\")\n",
        "    dist_coeffs = np.zeros((4, 1))  # assume no lens distortion\n",
        "\n",
        "    success, rotation_vector, translation_vector = cv2.solvePnP(\n",
        "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
        "    )\n",
        "\n",
        "    # project a point (0,0,1000) onto the image plane -> to draw nose direction\n",
        "    (nose_end_point2D, _) = cv2.projectPoints(\n",
        "        np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
        "    )\n",
        "\n",
        "    # rotation vector -> rotation matrix -> euler angles (approx)\n",
        "    R, _ = cv2.Rodrigues(rotation_vector)\n",
        "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
        "    singular = sy < 1e-6\n",
        "    if not singular:\n",
        "        x = math.atan2(R[2, 1], R[2, 2])\n",
        "        y = math.atan2(-R[2, 0], sy)\n",
        "        z = math.atan2(R[1, 0], R[0, 0])\n",
        "    else:\n",
        "        x = math.atan2(-R[1, 2], R[1, 1])\n",
        "        y = math.atan2(-R[2, 0], sy)\n",
        "        z = 0\n",
        "    # convert to degrees\n",
        "    roll = np.degrees(x)\n",
        "    pitch = np.degrees(y)\n",
        "    yaw = np.degrees(z)\n",
        "    return (tuple(nose_end_point2D.reshape(2)), (yaw, pitch, roll), (rotation_vector, translation_vector))\n"
      ],
      "metadata": {
        "id": "4dfVJegeMGNq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3: detector class\n",
        "class DrowsinessDetector:\n",
        "    def __init__(self, ear_thresh=0.25, ear_consec_frames=15, head_yaw_thresh=25):\n",
        "        self.EAR_THRESH = ear_thresh\n",
        "        self.EAR_CONSEC_FRAMES = ear_consec_frames\n",
        "        self.HEAD_YAW_THRESH = head_yaw_thresh\n",
        "        self.counter = 0\n",
        "        self.alarm_on = False\n",
        "        self.total_drowsy_events = 0\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        # input: BGR frame, output: annotated BGR frame, info dict\n",
        "        orig = frame.copy()\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        rects = detector(gray, 0)\n",
        "        info = {\"status\": \"No face\", \"ear\": None, \"yaw\": None, \"pitch\": None, \"roll\": None}\n",
        "\n",
        "        for rect in rects:\n",
        "            shape = predictor(gray, rect)\n",
        "            shape_np = shape_to_np(shape)\n",
        "\n",
        "            leftEye = shape_np[42:48]\n",
        "            rightEye = shape_np[36:42]\n",
        "            leftEAR = eye_aspect_ratio(leftEye)\n",
        "            rightEAR = eye_aspect_ratio(rightEye)\n",
        "            ear = (leftEAR + rightEAR) / 2.0\n",
        "            info[\"ear\"] = ear\n",
        "\n",
        "            # draw eye contours\n",
        "            for (x, y) in np.concatenate([leftEye, rightEye]):\n",
        "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\n",
        "            # head pose\n",
        "            nose_proj, (yaw, pitch, roll), _ = get_head_pose(shape_np, frame.shape[:2])\n",
        "            info[\"yaw\"], info[\"pitch\"], info[\"roll\"] = (yaw, pitch, roll)\n",
        "\n",
        "            # draw nose direction\n",
        "            nose_point = tuple(shape_np[30])\n",
        "            cv2.line(frame, nose_point, (int(nose_proj[0]), int(nose_proj[1])), (255, 0, 0), 2)\n",
        "\n",
        "            # drowsiness logic: EAR-based\n",
        "            if ear < self.EAR_THRESH:\n",
        "                self.counter += 1\n",
        "                if self.counter >= self.EAR_CONSEC_FRAMES:\n",
        "                    info[\"status\"] = \"ALERT: Drowsy!\"\n",
        "                    if not self.alarm_on:\n",
        "                        self.alarm_on = True\n",
        "                        self.total_drowsy_events += 1\n",
        "                else:\n",
        "                    info[\"status\"] = \"Eyes maybe closing...\"\n",
        "            else:\n",
        "                # reset counter\n",
        "                if self.counter >= self.EAR_CONSEC_FRAMES:\n",
        "                    # recovered from drowsiness\n",
        "                    pass\n",
        "                self.counter = 0\n",
        "                self.alarm_on = False\n",
        "                info[\"status\"] = \"Attentive\"\n",
        "\n",
        "            # distraction logic: head yaw (approx)\n",
        "            if abs(yaw) > self.HEAD_YAW_THRESH:\n",
        "                info[\"status\"] = \"ALERT: Distracted!\"\n",
        "                cv2.putText(frame, \"!!! WAKE UP !!!\", (100, 200),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0,0,255), 4)\n",
        "\n",
        "\n",
        "            # overlay info\n",
        "            cv2.putText(frame, f\"Status: {info['status']}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if \"ALERT\" in info[\"status\"] else (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"EAR:{ear:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
        "            cv2.putText(frame, f\"Yaw:{yaw:.1f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
        "\n",
        "        return frame, info\n"
      ],
      "metadata": {
        "id": "8ytSM8WvL25T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 4: JS capture helper\n",
        "capture_js = \"\"\"\n",
        "async function captureImage(quality=0.7) {\n",
        "  const video = document.createElement('video');\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "  document.body.appendChild(video);\n",
        "  video.style.display = 'block';\n",
        "  video.srcObject = stream;\n",
        "  await video.play();\n",
        "  const canvas = document.createElement('canvas');\n",
        "  canvas.width = video.videoWidth;\n",
        "  canvas.height = video.videoHeight;\n",
        "  const ctx = canvas.getContext('2d');\n",
        "  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "  stream.getTracks().forEach(track => track.stop());\n",
        "  const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "  return dataUrl;\n",
        "}\n",
        "captureImage();\n",
        "\"\"\"\n",
        "\n",
        "def js_capture_frame():\n",
        "    data = eval_js(capture_js)  # returns a dataURL 'data:image/jpeg;base64,...'\n",
        "    header, encoded = data.split(',', 1)\n",
        "    img_bytes = b64decode(encoded)\n",
        "    nparr = np.frombuffer(img_bytes, np.uint8)\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "g3wL4NG5Mbnb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 5: run the real-time simulation (press the notebook stop button to interrupt)\n",
        "det = DrowsinessDetector(ear_thresh=0.25, ear_consec_frames=10, head_yaw_thresh=25)\n",
        "\n",
        "frames_for_gif = []  # optional: collect annotated frames for a demo GIF\n",
        "try:\n",
        "    while True:\n",
        "        frame = js_capture_frame()  # capture from webcam via browser\n",
        "        annotated, info = det.process_frame(frame)\n",
        "        # convert BGR->JPEG bytes and display\n",
        "        _, jpg = cv2.imencode('.jpg', annotated)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "        frames_for_gif.append(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "        clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped by user\")\n",
        "except Exception as e:\n",
        "    print(\"Exception:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TxBhYKoVMfsF",
        "outputId": "18ef44e6-7bba-4d3b-a91e-3aff65dbf98e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception: NotAllowedError: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "det = DrowsinessDetector(ear_thresh=0.25, ear_consec_frames=10, head_yaw_thresh=25)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        frame = js_capture_frame()\n",
        "        annotated, info = det.process_frame(frame)\n",
        "        _, jpg = cv2.imencode('.jpg', annotated)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "        clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped by user\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "AqjiyLpxWGNA",
        "outputId": "2fce21fb-718d-431e-8adc-73ba6c7754eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "NotAllowedError: Permission denied",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-834613358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjs_capture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mannotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4109903544.py\u001b[0m in \u001b[0;36mjs_capture_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjs_capture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture_js\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns a dataURL 'data:image/jpeg;base64,...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimg_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: NotAllowedError: Permission denied"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 6: save GIF (run after you collected frames_for_gif)\n",
        "if frames_for_gif:\n",
        "    gif_path = '/content/drowsiness_demo.gif'\n",
        "    imageio.mimsave(gif_path, frames_for_gif, fps=6)\n",
        "    print(\"Saved demo GIF to\", gif_path)\n",
        "else:\n",
        "    print(\"No frames recorded. Run the capture loop first and collect frames.\")\n"
      ],
      "metadata": {
        "id": "5tq3kofjMjW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8onFMA8U9P5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}